# ğŸ¦ 100cep Gateway â€” MVP de Engenharia de Dados
Pipeline de dados construÃ­do no Databricks para simular o processamento de pedidos, pagamentos e chargebacks de uma empresa fictÃ­cia do setor de pagamentos, a **100cep Gateway**. O MVP segue boas prÃ¡ticas de Data Lakehouse, utilizando Delta Lake, Unity Catalog e a arquitetura **Bronze â†’ Silver â†’ Gold**.

---

# ğŸ¯ 1. Objetivo do Projeto

Este MVP tem como objetivo construir um pipeline de engenharia de dados completo para:

- ingerir dados transacionais de e-commerce;  
- padronizar, relacionar e organizar entidades (pedidos, pagamentos, itens, clientes, sellers);  
- gerar camadas analÃ­ticas para monitoramento de risco, antifraude e chargebacks;  
- responder perguntas de negÃ³cio tÃ­picas de empresas de pagamentos, adquirentes e gateways.

O foco central Ã© entender:

> **Como a 100cep Gateway pode monitorar, conciliar e antecipar ocorrÃªncias de pagamentos e chargebacks utilizando dados transacionais?**

Todas as perguntas de negÃ³cio estÃ£o documentadas em:  
ğŸ“„ `/docs/business_questions.md`

---

# ğŸ“¥ 2. Coleta dos Dados

Os dados utilizados foram obtidos no Kaggle (**Brazilian E-Commerce Public Dataset by Olist**), amplamente usado em estudos e projetos educacionais.

Processo adotado:

1. Download manual dos arquivos CSV.
2. Upload para o **Unity Catalog Volumes** no Databricks, garantindo:
   - armazenamento em nuvem,
   - versionamento pelo UC,
   - padronizaÃ§Ã£o da ingestÃ£o no nÃ­vel Bronze.

âš  NÃ£o houve uso de web scraping ou dados sensÃ­veis.  
âš  Nenhum dado interno ou confidencial de empresas reais foi utilizado.

EvidÃªncias (screenshots) estÃ£o na pasta: `/docs/screenshots/coleta`.

---

# ğŸ§± 3. Modelagem de Dados

Foi adotado um modelo **Lakehouse** com tabelas **flat por conceito**:

### ğŸ”¹ Bronze
- Armazenamento dos arquivos *exatamente como chegaram*.
- Sem limpeza, sem inferÃªncia, sem padronizaÃ§Ã£o.
- Garantia de auditabilidade.

### ğŸ”¹ Silver
- PadronizaÃ§Ã£o de tipos
- DeduplicaÃ§Ã£o
- Tratamento de nulos
- CorreÃ§Ã£o de colunas derivadas
- RelaÃ§Ã£o entre entidades (join lÃ³gico)

### ğŸ”¹ Gold
- Tabelas analÃ­ticas orientadas ao negÃ³cio
- KPIs de chargebacks, GMV, ticket mÃ©dio
- Modelos por mÃ©todo de pagamento, seller e regiÃ£o

### ğŸ“„ CatÃ¡logo de Dados
Foi criado um **Data Catalog** contendo:

- Nome da coluna  
- Tipo de dado  
- DomÃ­nio esperado  
- Valores mÃ­nimos e mÃ¡ximos (numÃ©ricos)  
- Categorias possÃ­veis (categÃ³ricos)  
- DescriÃ§Ã£o funcional  
- Camada de origem  
- Linhagem Bronze â†’ Silver â†’ Gold

Arquivo: `/docs/data_catalog.md`

---

# ğŸš€ 4. Carga (ETL / ELT)

A carga foi estruturada em trÃªs passos principais:

### 1) IngestÃ£o (Bronze)
- Leitura dos CSVs diretamente do Volume UC  
- PersistÃªncia em Delta  
- NormalizaÃ§Ã£o de nomes de colunas

### 2) TransformaÃ§Ã£o (Silver)
- ConversÃ£o de tipos datetime  
- CorreÃ§Ã£o de colunas categÃ³ricas  
- PadronizaÃ§Ã£o de campos numÃ©ricos  
- ExclusÃ£o de duplicadas  
- ConsolidaÃ§Ã£o de tabelas relacionadas

### 3) Modelagem AnalÃ­tica (Gold)
- Tabelas agregadas  
- MÃ©tricas de operaÃ§Ã£o e risco  
- JunÃ§Ãµes entre pedidos, pagamentos e chargebacks

DocumentaÃ§Ã£o do ETL: `/docs/etl_documentation.md`  
EvidÃªncias de execuÃ§Ã£o: `/docs/screenshots/carga`

---

# ğŸ“Š 5. AnÃ¡lises Realizadas

## ğŸ” a) Qualidade dos Dados
Foi feita uma anÃ¡lise de:

- valores ausentes  
- valores fora do domÃ­nio  
- inconsistÃªncias entre tabelas  
- dados duplicados  
- erros de formato  

As correÃ§Ãµes foram aplicadas na camada Silver.  
EvidÃªncias em `/docs/screenshots/data_quality`.

---

## ğŸ§  b) SoluÃ§Ã£o do Problema (Perguntas de NegÃ³cio)

As anÃ¡lises Gold respondem perguntas como:

- Qual o GMV da operaÃ§Ã£o?  
- Qual o ticket mÃ©dio por seller, cidade e mÃ©todo de pagamento?  
- Qual a taxa de chargeback total e por categoria?  
- Quais sellers apresentam maior risco?  
- Existem inconsistÃªncias entre pedidos e pagamentos?  
- Atraso na entrega tem correlaÃ§Ã£o com chargeback?  
- Quais mÃ©todos tÃªm maior proporÃ§Ã£o de disputas?  

As respostas detalhadas estÃ£o em:  
ğŸ“„ `/docs/analysis.md`

---

# ğŸ“ 6. AutoavaliaÃ§Ã£o

DiscussÃ£o final sobre:

- objetivos atingidos e nÃ£o atingidos;  
- dificuldades enfrentadas;  
- limitaÃ§Ãµes naturais do MVP;  
- melhorias e prÃ³ximos passos (streaming, automaÃ§Ã£o, dashboards, monitoramento).

Arquivo: `/docs/self_assessment.md`

---

# ğŸ‘¨â€ğŸ’» Autor

**Felipe Pinheiro**  
LinkedIn: *[link aqui](https://www.linkedin.com/in/feliperamospinheiro/)*  
GitHub: *[link aqui](https://github.com/feliperamospinheiro)*

# CrÃ©ditos

Dataset: *[Brazilian E-Commerce Public Dataset by Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)*
Autor: Olist & AndrÃ© Sionek
DOI Citation: *[DOI](https://doi.org/10.34740/kaggle/dsv/195341)*
LicenÃ§a: *[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)*
