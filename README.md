<h1 align="center">Data Engineering MVP</h1>

<p align="center">
  <a href="https://shields.io/">
    <img src="https://img.shields.io/badge/status-concluded-green.svg" alt="Status">
  </a>
  <a href="https://www.databricks.com/">
    <img src="https://img.shields.io/badge/Databricks-Data%20Platform-orange?logo=databricks&logoColor=white" alt="Databricks">
  </a>
  <a href="https://en.wikipedia.org/wiki/Data_engineering">
    <img src="https://img.shields.io/badge/Data%20Engineering-blue" alt="Data Engineering">
  </a>
  <a href="https://spark.apache.org/">
    <img src="https://img.shields.io/badge/Apache%20Spark-Spark-orange?logo=apachespark&logoColor=white" alt="Apache Spark">
  </a>
  <a href="https://www.postgresql.org/docs/">
    <img src="https://img.shields.io/badge/SQL-Query%20Language-blue?logo=postgresql&logoColor=white" alt="SQL">
  </a>
  <a href="https://pandas.pydata.org/docs/">
    <img src="https://img.shields.io/badge/Pandas-Data%20Analysis-purple?logo=pandas&logoColor=white" alt="Pandas">
  </a>
  <a href="https://seaborn.pydata.org/">
    <img src="https://img.shields.io/badge/Seaborn-Data%20Visualization-lightblue" alt="Seaborn">
  </a>
  <a href="https://geopandas.org/en/stable/">
    <img src="https://img.shields.io/badge/GeoPandas-Geospatial%20Data-green" alt="GeoPandas">
  </a>
</p>

The MVP simulates the transactional pipeline of 100cep Gateway, including ingestion, processing, reconciliation and chargebacks, following acquiring and financial infrastructure standards.

Data pipeline built on Databricks to simulate the processing of orders, payments and chargebacks for a fictitious company in the payments sector, **100cep Gateway**.

The project follows Data Lakehouse best practices, using Delta Lake, Unity Catalog and the **Bronze â†’ Silver â†’ Gold** architecture.

**Repository organization:**

```
ğŸ“ 100cep-gateway
â”œâ”€â”€ ğŸ“ .databricks
â”‚   â””â”€â”€ ğŸ“ pipeline
â”‚       â”œâ”€â”€ ğŸ“ html # contains Databricks files in .html format
â”‚       â””â”€â”€ ğŸ“ notebooks # contains Databricks files in .ipynb format
â”œâ”€â”€ ğŸ“ datasets 
â”‚   â”œâ”€â”€ ğŸ“ ai_dataset # contains the dataset generated by the OpenAI 5.0 model
â”‚   â””â”€â”€ ğŸ“ olist_dataset # contains the Brazilian E-Commerce Public Dataset by Olist
â”œâ”€â”€ ğŸ“ dbdiagram # contains the code created in dbdiagram.io
â”œâ”€â”€ ğŸ“ images
â”‚   â”œâ”€â”€ ğŸ“ databricks # Databricks evidence
â”‚   â”œâ”€â”€ ğŸ“ dbdiagram # dbdiagram.io schema
â”‚   â””â”€â”€ ğŸ“ logo # 100cep Gateway logo
```

---
<h2 align="center">100cep Gateway</h2>

<p align="center"> <img src="./images/logo/100cep-gateway.png" alt="100cep Gateway Logo" width="100%"></p>

**100cep Gateway** is a fictitious borderless payments infrastructure company, specialized in processing global payments in a fast, secure and interoperable way.

Our goal is to enable **fast**, **secure** and **borderless** transactions â€” after all, we are _100cep_: with no _city_, _state_ or _country_ limiting the flow of payments.

### ğŸ”‘ Key Features
- ğŸŒ **Global Payments**: Processing without geographic restrictions
- âš¡ **High Performance**: Infrastructure prepared for high transaction volume
- ğŸ”’ **Security**: Real-time fraud and chargeback monitoring
- ğŸ“Š **Analytics**: Dashboards and metrics for decision-making

---

<h2 align="center">Technologies Used</h2>

### Platform and Storage
- **Databricks**: Unified data platform
- **Delta Lake**: Transactional storage format
- **Unity Catalog**: Data governance and cataloging
- **UC Volumes**: Raw file storage

### Processing and Analysis
- **Apache Spark**: Distributed processing engine
- **PySpark**: Python API for Spark
- **SQL**: Analytical queries and transformations
- **Pandas**: Exploratory data analysis

### Visualization and Modeling
- **Seaborn**: Statistical visualizations
- **Matplotlib**: Charts and plots
- **GeoPandas**: Geospatial analyses
- **dbdiagram.io**: Data modeling

---
<h2 align="center">Project Objective</h2>

This MVP aims to build a complete data engineering pipeline to:

- ingest transactional e-commerce data;  
- standardize, relate and organize entities (orders, payments, items, customers, sellers);  
- generate analytical layers for monitoring risk, antifraud and chargebacks;  
- answer business questions typical of payment companies, acquirers and gateways.

The central focus is to understand:

> **How can 100cep Gateway monitor, reconcile and anticipate payment and chargeback events using transactional data?**

All business questions are documented in:  
ğŸ“„ [/docs/business_questions.md](docs/business_questions.md)

---

<h2 align="center">Data Collection</h2>

The data used were obtained from Kaggle (**Brazilian E-Commerce Public Dataset by Olist**), widely used in studies and educational projects.

Process followed:

1. Manual download of CSV files.
2. Upload to **Unity Catalog Volumes** in Databricks, ensuring:
  - cloud storage,
  - versioning via UC,
  - standardized ingestion at the Bronze level.

âš  No web scraping or sensitive data was used.  
âš  No internal or confidential data from real companies was used.

ğŸ“¸ **Evidence**: Screenshots of the collection process are available in the `/docs/images/databricks/` folder.

---

<h2 align="center">Data Modeling</h2>

A **Lakehouse** model with **flat tables by concept** was adopted:

### ğŸ¥‰ Bronze
- Storage of files *exactly as they arrived*.
- No cleaning, no inference, no standardization.
- Auditability guarantee.

### ğŸ¥ˆ Silver
- Type standardization
- Deduplication
- Handling of nulls
- Correction of derived columns
- Relationship between entities (logical joins)

### ğŸ¥‡ Gold
- Business-oriented analytical tables
- KPIs for chargebacks, GMV, average ticket
- Models by payment method, seller and region

### ğŸ“„ Data Catalog
A **Data Catalog** was created containing:

- Column name  
- Data type  
- Expected domain  
- Minimum and maximum values (numerical)  
- Possible categories (categorical)  
- Functional description  
- Source layer  
- Bronze â†’ Silver â†’ Gold lineage

ğŸ“„ **Complete documentation**: [/docs/data_catalog.md](docs/data_catalog.md)

---
<h2 align="center">Loading (ETL / ELT)</h2>

The load was structured in three main steps:

### 1) Ingestion (Bronze)
- Reading CSVs directly from the UC Volume  
- Persistence in Delta  
- Normalization of column names

### 2) Transformation (Silver)
- Conversion of datetime types  
- Correction of categorical columns  
- Standardization of numeric fields  
- Removal of duplicates  
- Consolidation of related tables

### 3) Analytical Modeling (Gold)
- Aggregated tables  
- Operational and risk metrics  
- Joins between orders, payments and chargebacks

ğŸ“„ **Complete ETL documentation**: [/docs/etl.md](docs/etl.md)  
ğŸ“¸ **Execution evidence**: Screenshots available in `/docs/images/databricks/`

---
<h2 align="center">Analyses Performed</h2>

## a) Data Quality
An analysis was performed of:

- missing values  
- out-of-domain values  
- inconsistencies between tables  
- duplicated data  
- format errors  

Corrections were applied in the Silver layer, ensuring:
- âœ… Consistent and reliable data
- âœ… Correct data types
- âœ… Values within expected domains
- âœ… Integrity of relationships between tables

ğŸ“¸ **Evidence**: Screenshots available in `/docs/images/databricks/`

---

## b) Problem Solution (Business Questions)

The Gold analyses answer questions such as:

- **What is the most used payment method by 100cep Gateway customers?** 
- **What is the revenue history for the year 2017?**  
- **What is the proportion of orders with and without chargeback requests?**  
- **Which payment methods have the highest chargeback risk?**  
- **Which states present the highest chargeback rates?**  

Detailed answers are in:  
ğŸ“„ [/docs/business_questions.md](docs/business_questions.md)

### ğŸ“Š Main Insights
- Credit card is the predominant payment method
- Chargeback rate varies significantly by state
- Correlation between payment method and chargeback risk
- Seasonal patterns in 2017 revenue

---
<h2 align="center">Self-Assessment</h2>

Final discussion about:

- goals achieved and not achieved;  
- challenges faced;  
- natural limitations of the MVP;  
- improvements and next steps (streaming, automation, dashboards, monitoring).

ğŸ“„ **Complete documentation**: [/docs/self_assessment.md](docs/self_assessment.md)

---

<h2 align="center">Author</h2>

**Felipe Pinheiro**  

[![Gmail](https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:felipervmospinheiro@gmail.com)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/feliperamospinheiro)

<h2 align="center">Credits</h2>

Dataset: *[Brazilian E-Commerce Public Dataset by Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)*

Author: Olist & AndrÃ© Sionek

DOI Citation: *[DOI](https://doi.org/10.34740/kaggle/dsv/195341)*

License: *[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)*
